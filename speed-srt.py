import os
import sys
import html
from pathlib import Path
from typing import Optional, Dict
from groq import Groq


class AudioToSRTConverter:
    """ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Groq API"""
    
    def __init__(self, api_key: str):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ converter
        
        Args:
            api_key: Ú©Ù„ÛŒØ¯ API Ø§Ø² Groq
        """
        self.client = Groq(api_key=api_key)
        
        # Ù†Ù‚Ø´Ù‡ ØªØµØ­ÛŒØ­ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù†Ø±ÙˆÚ˜ÛŒ Ùˆ Ø³Ø§ÛŒØ± Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§
        self.char_replacements = {
            'ÃƒÂ¥': 'Ã¥', 'ÃƒÂ¦': 'Ã¦', 'ÃƒÂ¸': 'Ã¸',
            'Ãƒâ€¦': 'Ã…', 'Ãƒâ€ ': 'Ã†', 'ÃƒËœ': 'Ã˜',
            'nÃƒÂ¥': 'nÃ¥', 'pÃƒÂ¥': 'pÃ¥', 'sÃƒÂ¥': 'sÃ¥',
            'mÃƒÂ¥': 'mÃ¥', 'gÃƒÂ¥': 'gÃ¥', 'fÃƒÂ¸': 'fÃ¸',
            'gjÃƒÂ¸': 'gjÃ¸', 'hÃƒÂ¸': 'hÃ¸', 'skjÃƒÂ¸': 'skjÃ¸',
            'ÃƒÂ¸de': 'Ã¸de'
        }
    
    @staticmethod
    def clean_text(text: str, replacements: Dict[str, str]) -> str:
        """
        ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ù…ØªÙ†
        
        Args:
            text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            replacements: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§
            
        Returns:
            Ù…ØªÙ† ØªÙ…ÛŒØ² Ø´Ø¯Ù‡
        """
        # ØªØ¨Ø¯ÛŒÙ„ HTML entities
        text = html.unescape(text)
        
        # Ø§Ø¹Ù…Ø§Ù„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text.strip()
    
    @staticmethod
    def seconds_to_srt_time(seconds: float) -> str:
        """
        ØªØ¨Ø¯ÛŒÙ„ Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ù‡ ÙØ±Ù…Øª Ø²Ù…Ø§Ù† SRT (HH:MM:SS,mmm)
        
        Args:
            seconds: Ø²Ù…Ø§Ù† Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡
            
        Returns:
            Ø±Ø´ØªÙ‡ Ø²Ù…Ø§Ù† Ø¨Ù‡ ÙØ±Ù…Øª SRT
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def transcribe_audio(
        self,
        audio_path: str,
        language: str = "no",
        model: str = "whisper-large-v3-turbo",
        prompt: Optional[str] = None,
        temperature: float = 0.0
    ) -> Dict:
        """
        ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Groq API
        
        Args:
            audio_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            language: Ú©Ø¯ Ø²Ø¨Ø§Ù† (ISO-639-1)
            model: Ù…Ø¯Ù„ Whisper (whisper-large-v3-turbo ÛŒØ§ whisper-large-v3)
            prompt: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
            temperature: Ø¯Ù…Ø§ÛŒ Ù…Ø¯Ù„ (0-1)
            
        Returns:
            Ù†ØªÛŒØ¬Ù‡ transcription Ø´Ø§Ù…Ù„ segments Ùˆ metadata
        """
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"âŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {audio_path}")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØ² ÙØ§ÛŒÙ„ (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª 25MB Ø¨Ø±Ø§ÛŒ free tier)
        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        print(f"ğŸ“ Ø³Ø§ÛŒØ² ÙØ§ÛŒÙ„: {file_size_mb:.2f} MB")
        
        if file_size_mb > 25:
            print(f"âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ø³Ø§ÛŒØ² ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø² 25MB Ø§Ø³Øª.")
            print("   ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª FLAC ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯.")
        
        print(f"ğŸ™ï¸  Ø¯Ø± Ø­Ø§Ù„ transcribe Ú©Ø±Ø¯Ù† {Path(audio_path).name}...")
        print(f"   Ù…Ø¯Ù„: {model}")
        print(f"   Ø²Ø¨Ø§Ù†: {language}")
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª tuple (Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ù…Ø´Ú©Ù„ Content-Length)
        filename = Path(audio_path).name
        with open(audio_path, "rb") as audio_file:
            audio_data = audio_file.read()
        
        transcription = self.client.audio.transcriptions.create(
            file=(filename, audio_data),
            model=model,
            response_format="verbose_json",
            language=language,
            prompt=prompt,
            temperature=temperature,
            timestamp_granularities=["segment"]
        )
        
        return transcription
    
    def generate_srt(
        self,
        transcription: Dict,
        output_path: str,
        clean_chars: bool = True
    ) -> None:
        """
        ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ SRT Ø§Ø² Ù†ØªÛŒØ¬Ù‡ transcription
        
        Args:
            transcription: Ù†ØªÛŒØ¬Ù‡ transcription Ø§Ø² Groq
            output_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ SRT
            clean_chars: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§
        """
        srt_content = []
        segment_number = 1
        
        for segment in transcription.segments:
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"]
            
            # ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
            if clean_chars:
                text = self.clean_text(text, self.char_replacements)
            
            # Ø³Ø§Ø®Øª ÙØ±Ù…Øª SRT
            srt_content.append(str(segment_number))
            srt_content.append(
                f"{self.seconds_to_srt_time(start_time)} --> "
                f"{self.seconds_to_srt_time(end_time)}"
            )
            srt_content.append(text)
            srt_content.append("")  # Ø®Ø· Ø®Ø§Ù„ÛŒ Ø¨ÛŒÙ† segments
            
            segment_number += 1
        
        # Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ SRT
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("\n".join(srt_content))
        
        print(f"âœ… ÙØ§ÛŒÙ„ SRT Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {output_path}")
    
    def analyze_transcription_quality(self, transcription: Dict) -> None:
        """
        ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª transcription Ø¨Ø± Ø§Ø³Ø§Ø³ metadata
        
        Args:
            transcription: Ù†ØªÛŒØ¬Ù‡ transcription Ø§Ø² Groq
        """
        print("\nğŸ“Š ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª:")
        print(f"   ØªØ¹Ø¯Ø§Ø¯ segments: {len(transcription.segments)}")
        print(f"   Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ú©Ù„: {transcription.duration:.1f} Ø«Ø§Ù†ÛŒÙ‡")
        
        # ØªØ­Ù„ÛŒÙ„ segments Ø¨Ø§ Ú©ÛŒÙÛŒØª Ù¾Ø§ÛŒÛŒÙ†
        low_confidence_segments = []
        high_no_speech_segments = []
        
        for i, segment in enumerate(transcription.segments):
            avg_logprob = segment.get("avg_logprob", 0)
            no_speech_prob = segment.get("no_speech_prob", 0)
            
            # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ segments Ù…Ø´Ú©ÙˆÚ©
            if avg_logprob < -0.5:
                low_confidence_segments.append((i, avg_logprob))
            
            if no_speech_prob > 0.5:
                high_no_speech_segments.append((i, no_speech_prob))
        
        if low_confidence_segments:
            print(f"\nâš ï¸  {len(low_confidence_segments)} segment Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù¾Ø§ÛŒÛŒÙ†:")
            for idx, prob in low_confidence_segments[:3]:  # Ù†Ù…Ø§ÛŒØ´ 3 Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„
                print(f"   Segment {idx}: avg_logprob = {prob:.3f}")
        
        if high_no_speech_segments:
            print(f"\nâš ï¸  {len(high_no_speech_segments)} segment Ø¨Ø§ Ø§Ø­ØªÙ…Ø§Ù„ no-speech Ø¨Ø§Ù„Ø§:")
            for idx, prob in high_no_speech_segments[:3]:
                print(f"   Segment {idx}: no_speech_prob = {prob:.3f}")
        
        if not low_confidence_segments and not high_no_speech_segments:
            print("   âœ“ Ú©ÛŒÙÛŒØª transcription Ø¹Ø§Ù„ÛŒ Ø§Ø³Øª!")
    
    def convert(
        self,
        audio_path: str,
        output_path: Optional[str] = None,
        language: str = "no",
        model: str = "whisper-large-v3-turbo",
        analyze_quality: bool = True
    ) -> None:
        """
        ØªØ¨Ø¯ÛŒÙ„ Ú©Ø§Ù…Ù„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù‡ SRT
        
        Args:
            audio_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            output_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            language: Ú©Ø¯ Ø²Ø¨Ø§Ù†
            model: Ù…Ø¯Ù„ Whisper
            analyze_quality: Ù†Ù…Ø§ÛŒØ´ ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª
        """
        # ØªØ¹ÛŒÛŒÙ† Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ
        if output_path is None:
            output_path = Path(audio_path).stem + ".srt"
        
        # Transcription
        transcription = self.transcribe_audio(
            audio_path=audio_path,
            language=language,
            model=model
        )
        
        # ØªÙˆÙ„ÛŒØ¯ SRT
        self.generate_srt(transcription, output_path)
        
        # ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª
        if analyze_quality:
            self.analyze_transcription_quality(transcription)


def print_usage():
    """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡"""
    print("=" * 60)
    print("ğŸ¬ ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù‡ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ SRT Ø¨Ø§ Groq API")
    print("=" * 60)
    print("\nğŸ“– Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:")
    print("   python3 a.py <Ø¢Ø¯Ø±Ø³_ÙØ§ÛŒÙ„_ØµÙˆØªÛŒ> <Ù†Ø§Ù…_ÙØ§ÛŒÙ„_Ø®Ø±ÙˆØ¬ÛŒ>")
    print("\nğŸ’¡ Ù…Ø«Ø§Ù„:")
    print("   python3 a.py audio.flac output.srt")
    print("   python3 a.py /path/to/video.mp4 subtitle")
    print("\nğŸ“ ØªÙˆØ¬Ù‡:")
    print("   - Ø§Ú¯Ø± Ù†Ø§Ù… Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ù†Ú©Ù†ÛŒØ¯ØŒ Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    print("   - Ù¾Ø³ÙˆÙ†Ø¯ .srt Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    print("\nğŸŒ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡:")
    print("   flac, mp3, mp4, wav, webm, m4a, ogg, mpeg, mpga")
    print("=" * 60)


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² converter Ø¨Ø§ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†"""
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§
    if len(sys.argv) < 2:
        print_usage()
        sys.exit(1)
    
    # Ú¯Ø±ÙØªÙ† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§
    audio_file = sys.argv[1]
    
    # ØªØ¹ÛŒÛŒÙ† Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ
    if len(sys.argv) >= 3:
        output_file = sys.argv[2]
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø³ÙˆÙ†Ø¯ .srt Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        if not output_file.endswith('.srt'):
            output_file += '.srt'
    else:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ
        output_file = Path(audio_file).stem + ".srt"
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª - API KEY Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
    API_KEY = ""
    
    if API_KEY == "your_groq_api_key_here":
        print("âŒ Ø®Ø·Ø§: API Key ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª!")
        print("\nğŸ’¡ Ø±Ø§Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… API Key:")
        print("   1. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ: export GROQ_API_KEY='your_key'")
        print("   2. Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ú©Ø¯: API_KEY = 'your_key'")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
    print("=" * 60)
    print(f"ğŸ“‚ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ: {audio_file}")
    print(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print("=" * 60 + "\n")
    
    try:
        # Ø§ÛŒØ¬Ø§Ø¯ converter
        converter = AudioToSRTConverter(api_key=API_KEY)
        
        # ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„
        converter.convert(
            audio_path=audio_file,
            output_path=output_file,
            language="no",  # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯: en, fa, ar, ...
            model="whisper-large-v3",  # ÛŒØ§ whisper-large-v3 Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
            analyze_quality=True
        )
        
        print("\n" + "=" * 60)
        print("ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
        print("=" * 60)
        
    except FileNotFoundError as e:
        print(f"\nâŒ Ø®Ø·Ø§: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
